{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "sys.path.append(\"../Acdc/\")\n",
    "import Acdc \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dictionaries for loading configurations nicely\n",
    "### Also define some filepaths that should be adjusted based on your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Structure of this dict:\n",
    "#key: acdc number\n",
    "#value: dict with the following keys\n",
    "#   obj: Acdc object itself\n",
    "#   config: configuration file path \n",
    "#   infiles: list of input data files for that board\n",
    "\n",
    "#this set of boards is used in the July 2024 proton data at test-beam\n",
    "acdcs = {44:{\"obj\":None, \"config\":\"../configs/acdc44.yml\", \"infiles\": [], \"pedfiles\": []}, \\\n",
    "\t43:{\"obj\":None, \"config\":\"../configs/acdc43.yml\", \"infiles\": [], \"pedfiles\": []}}\n",
    "\n",
    "#Configure some data filepaths\n",
    "#you'll likely want to keep paths as we may be committing/pushing\n",
    "#multiple paths. Just use a comment\n",
    "datadir = \"../../data/20240701ProtonDataFTBF/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['hpos', 'vpos', 'n_clusters', 'sys_time', 'wr_time', 'filename', 'file_time', 'evidx', 'pps', 'first_peak', 'wr_phi', 'wr_freq', 'max_ch', 'start_cap', 'error_codes', 'total_charge', 'ch0_baseline', 'ch0_std', 'ch0_max', 'ch0_min', 'ch0_is_hit', 'ch1_baseline', 'ch1_std', 'ch1_max', 'ch1_min', 'ch1_is_hit', 'ch2_baseline', 'ch2_std', 'ch2_max', 'ch2_min', 'ch2_is_hit', 'ch3_baseline', 'ch3_std', 'ch3_max', 'ch3_min', 'ch3_is_hit', 'ch4_baseline', 'ch4_std', 'ch4_max', 'ch4_min', 'ch4_is_hit', 'ch5_baseline', 'ch5_std', 'ch5_max', 'ch5_min', 'ch5_is_hit', 'ch6_baseline', 'ch6_std', 'ch6_max', 'ch6_min', 'ch6_is_hit', 'ch7_baseline', 'ch7_std', 'ch7_max', 'ch7_min', 'ch7_is_hit', 'ch8_baseline', 'ch8_std', 'ch8_max', 'ch8_min', 'ch8_is_hit', 'ch9_baseline', 'ch9_std', 'ch9_max', 'ch9_min', 'ch9_is_hit', 'ch10_baseline', 'ch10_std', 'ch10_max', 'ch10_min', 'ch10_is_hit', 'ch11_baseline', 'ch11_std', 'ch11_max', 'ch11_min', 'ch11_is_hit', 'ch12_baseline', 'ch12_std', 'ch12_max', 'ch12_min', 'ch12_is_hit', 'ch13_baseline', 'ch13_std', 'ch13_max', 'ch13_min', 'ch13_is_hit', 'ch14_baseline', 'ch14_std', 'ch14_max', 'ch14_min', 'ch14_is_hit', 'ch15_baseline', 'ch15_std', 'ch15_max', 'ch15_min', 'ch15_is_hit', 'ch16_baseline', 'ch16_std', 'ch16_max', 'ch16_min', 'ch16_is_hit', 'ch17_baseline', 'ch17_std', 'ch17_max', 'ch17_min', 'ch17_is_hit', 'ch18_baseline', 'ch18_std', 'ch18_max', 'ch18_min', 'ch18_is_hit', 'ch19_baseline', 'ch19_std', 'ch19_max', 'ch19_min', 'ch19_is_hit', 'ch20_baseline', 'ch20_std', 'ch20_max', 'ch20_min', 'ch20_is_hit', 'ch21_baseline', 'ch21_std', 'ch21_max', 'ch21_min', 'ch21_is_hit', 'ch22_baseline', 'ch22_std', 'ch22_max', 'ch22_min', 'ch22_is_hit', 'ch23_baseline', 'ch23_std', 'ch23_max', 'ch23_min', 'ch23_is_hit', 'ch24_baseline', 'ch24_std', 'ch24_max', 'ch24_min', 'ch24_is_hit', 'ch25_baseline', 'ch25_std', 'ch25_max', 'ch25_min', 'ch25_is_hit', 'ch26_baseline', 'ch26_std', 'ch26_max', 'ch26_min', 'ch26_is_hit', 'ch27_baseline', 'ch27_std', 'ch27_max', 'ch27_min', 'ch27_is_hit', 'ch28_baseline', 'ch28_std', 'ch28_max', 'ch28_min', 'ch28_is_hit', 'ch29_baseline', 'ch29_std', 'ch29_max', 'ch29_min', 'ch29_is_hit'])\n"
     ]
    }
   ],
   "source": [
    "#load the waveforms into the events attribute\n",
    "for acdc_num, a in acdcs.items():\n",
    "\ta[\"obj\"] = Acdc.Acdc(a[\"config\"])\n",
    "\n",
    "\t#the configuration is now parsed, so we can find which station id\n",
    "\t#in order to parse the filetag at the end of the data filenames. \n",
    "\tbnum = a[\"obj\"].c[\"station_id\"]\n",
    "\t#find all the data files for this board that are prereduced pickles\n",
    "\ta[\"infiles\"] = glob.glob(datadir + f\"Raw_Proton*b{bnum}*prereduced.p\")\n",
    "\n",
    "\n",
    "\t#go file by file and save reduced data for each file.\n",
    "\tfor f in a[\"infiles\"]:\n",
    "\t\t#the function can take a list of files, \n",
    "\t\t#so I pass just the one we are working on\n",
    "\t\ta[\"obj\"].read_events_from_file(f)\n",
    "\n",
    "\t\t#reduce the data\n",
    "\t\ta[\"obj\"].reduce_data()\n",
    "\t\tprint(a[\"obj\"].rqs.keys())\n",
    "\t\tbreak\n",
    "\tbreak\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llnl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
